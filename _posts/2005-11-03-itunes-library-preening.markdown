---
layout: post
status: publish
published: true
title: iTunes Library Preening
author: alastair
author_login: admin
author_email: alastair@girtby.net
author_url: http://girtby.net
wordpress_id: 150
wordpress_url: http://girtby.net/2007/02/17/itunes-library-preening
date: 2005-11-03 21:45:52.000000000 -06:00
categories:
- Nerd Factor X
tags: []
comments:
- id: 1302
  author: Chris
  author_email: tis@goringe.net
  author_url: http://tis.goringe.net
  date: '2005-11-03 21:45:52 -0600'
  date_gmt: '2005-11-03 21:45:52 -0600'
  content: <p>What about unrated tracks? Or do you obsessively rate everything?</p>
- id: 1303
  author: alastair
  author_email: alastair@girtby.net
  author_url: ''
  date: '2005-11-03 21:45:52 -0600'
  date_gmt: '2005-11-03 21:45:52 -0600'
  content: <p>Unrated tracks are ignored, hence "% of rated" and "cumulative % of
    rated".</p>
- id: 1304
  author: Eddie
  author_email: reg@el73.net
  author_url: http://my.opera.com/usability
  date: '2005-11-03 21:45:52 -0600'
  date_gmt: '2005-11-03 21:45:52 -0600'
  content: |-
    <p>It's interesting to see someone think about iTunes track rating the way I do.  I haven't found a good method yet (mine matches what you orginally had plus or minus).</p>

    <p>The problem I have is that I have tracks that I would consider 5 star, but not for the particular circumstances.. ie- the gym, vs. sleeping.  I see you give those a 4.  But then I get (as you have) very few 5 stars that I would listen to any time, anywhere.</p>

    <p>That's pretty much why I stopped obsessively rating them- I now have complex smart playlists.  So complex, that I would welcome the addition of regular expressions to further granulate :)</p>
- id: 1305
  author: james
  author_email: jamesbhess@hotmail.com
  author_url: ''
  date: '2005-11-03 21:45:52 -0600'
  date_gmt: '2005-11-03 21:45:52 -0600'
  content: |-
    <p>Honestly, it doesn't make any sense to me that one star be the rating for dislike. To me, if I don't like something enough to give it a negative rating it is most likely not in music library to begin with. Therefor, it makes more sense to me to use the 5 star rating system as a way of indicating increasing level of satisfaction with the song. One star being this song is a cut above the great majority which I am indiffernt to and there for get no ranking at all. Two through four stars are simply increasingly preferred songs, with five stars being my most prefered songs. </p>

    <p>My concern/confussion is in how iTunes actually makes this distinction in how it calculates shuffle play. Does iTunes play songs ranked with one star more often than songs with no stars?</p>
- id: 1306
  author: alastair
  author_email: alastair@girtby.net
  author_url: ''
  date: '2005-11-03 21:45:52 -0600'
  date_gmt: '2005-11-03 21:45:52 -0600'
  content: <p>Eddie, the underrated "grouping" field is great for this kind of task.
    The 1-5 star rating doesn't have a lot of resolution for saying "well I love this
    track except that it really is too rockin' to play when I'm brushing my teeth
    in the morning, except if I've just been for a run beforehand, and ..." So IMHO
    you're better off just using the rating to say how much you like the track. Categorising
    it to certain situations is the job of playlists (smart or dumb).</p>
- id: 1307
  author: alastair
  author_email: alastair@girtby.net
  author_url: ''
  date: '2005-11-03 21:45:52 -0600'
  date_gmt: '2005-11-03 21:45:52 -0600'
  content: |-
    <p>James:</p>

    <p>Well perhaps I should point out that I have a 60GB iPod so I have plenty of space for the one star tracks...</p>

    <p>Let me use an example which you might be familiar with: Radiohead's "OK Computer" album. Fantastic album. For whatever reason I resisted its charms, but now I'm totally into it. Now a lot of people (not including me BTW) dislike the track called "Fitter Happier". You might know the one, it has a robot voice reciting self-improvement goals. Some people don't like it and skip the track reflexively when it comes on.</p>

    <p>So this hypothetical person (again not me, I quite like the track although it's by no means the best) might rate this as one star to indicate that they don't really like it. They could instead just delete the song entirely from the library, but this leaves something of a gap in the album. I don't know about you, but I have a bit of an all-or-nothing approach, so I would prefer to keep the track but mark it as not a desirable candidate for shuffle play. If I wanted to skip the track during normal (sequential) play, I would probably create a smart playlist that excluded the one star tracks, or even a regular playlist with that track excluded.</p>

    <p>iTunes calculation of shuffle play is most certainly a mystery. Particularly in version 5.0+ where they introduced the "smart shuffle" feature. It is a mystery that will remain unsolved (by me).</p>
- id: 1308
  author: james
  author_email: jamesbhess@hotmail.com
  author_url: ''
  date: '2005-11-03 21:45:52 -0600'
  date_gmt: '2005-11-03 21:45:52 -0600'
  content: |-
    <p>alastair,
    Good point and well taken. I too am reluctant to break apart album, although couldn't the check marks have the same effect? I believe you can you not uncheck songs that you want not to be generally played while still keeping them in the library. There is an option when making smart playlists to only include checked songs.
    I think maybe I have a mental deficiency when it comes to star rating systems.
    If I knew how the iTunes shuffle worked I could be more comfortable with a ratings system any which way.</p>
---
Preening one's iTunes library is one of those continually rewarding pastimes. Adding cover art, fixing up meta-data, adding playlists, it's all endless fun. iTunes has a particularly entertaining feature where each track in your library can be given a rating, from one to five stars. This is a great way of instantly locating the best-of-the-best tracks in your collection. If you're like me you preen your ratings constantly.

The trouble I've always had though is deciding on the criteria for a given rating. Here are the criteria I have been loosely applying up till now. First the easy ones, then the harder ones:

 - **5 Stars** Desert-island track. Listen anytime, anywhere. Ridiculous sentimental attachment.
 - **1 Star** A bit crap. Sometimes totally crap, but I just can't bear to part with it because it completes an otherwise worthy album. Maybe it's one of those "we're just tooling around with the microphones on but we'll put it on the album for a laugh" type of tracks. On shuffle-play I don't want to hear these, ever.
 - **2 Stars** A default rating. Nothing standout about this track. Could stand to lose it from the collection, but don't actually dislike it.
 - **4 Stars** Something about this prevents it accompanying me to the desert island. Maybe I only like it in certain circumstances, or maybe I used to love it but am now going a bit bored of it.
 - **3 Stars** Somewhere in-between 2 and 4. The less said about this category the better, OK?

After struggling with these definitions for a while, I decided that they weren't really working. The 2, 3, and 4 star ratings were the hard ones, and this is where the bulk of my ratings go. This led me to thinking about the distribution of the tracks with each rating. Which led to the idea that maybe the ratings should *reflect* the distribution.

So instead of defining 5 stars against some arbitrary external criteria, it seems to be just as useful (if not more so) to define these in relative terms. So instead of "desert island track", I now look at 5 star-rated tracks as those in the top 5% of my library. 4 stars are in the top 15%, 3 stars in the top 50%, and 2 stars in the top 90%. 1 Star reserved for the bottom 10%.

[Don't ask me why 5 stars is the top 5% and 1 star is the bottom 10%, they are just the figures that popped out of my brain, perhaps some subconsciously-mangled [Sturgeon's Law](http://en.wikipedia.org/wiki/Sturgeon's_law)?]

But I needed some help to assess how far away from these definitions in my current ratings assignments. So I wrote a script to analyse my iTunes library to determine how far away I was from my target ratings distribution. Here is the first result:

<table border="1">
<caption>4339 tracks, 613 (14%) rated</caption>
<tr>
<td colspan="3"></td>
<th colspan="3">Cumulative % of rated</th>
</tr>
<tr>
<td></td>
<th>Number</th>
<th>% of rated</th>
<th>Actual</th>
<th>Target</th>
<th>Shortfall</th>
</tr>
  <tr>
<td>Tracks rated 5 stars:</td>
<td>6</td>
<td>1</td>
<td>1</td>
<td>5</td>
<td>4</td>
</tr>
  <tr>
<td>Tracks rated 4 stars:</td>
<td>136</td>
<td>22</td>
<td>23</td>
<td>15</td>
<td>-8</td>
</tr>
  <tr>
<td>Tracks rated 3 stars:</td>
<td>277</td>
<td>45</td>
<td>68</td>
<td>50</td>
<td>-18</td>
</tr>
  <tr>
<td>Tracks rated 2 stars:</td>
<td>160</td>
<td>26</td>
<td>94</td>
<td>90</td>
<td>-4</td>
</tr>
  <tr>
<td>Tracks rated 1 stars:</td>
<td>34</td>
<td>6</td>
<td>100</td>
</tr>
</table>

As you can see, I either need to realign my ratings definitions, change some of the existing assignments, or overcompensate when rating new tracks. Or all of these. Anyway, I don't want to be seen to be obsessing over this too much (a bit late now, he realises!) but the idea is to see that I've been, for example, a bit stingy with the 5-star ratings, and a bit generous with the 3-star ratings.

All of this obsessive behaviour can be yours, thanks to the latest girtby offering: [iTunes Library Stats](/offerings/itunes-ratings-stats/). It's an XSLT script which will produce the above output for your own iTunes Library. Works on Windows and MacOS. Enjoy!
